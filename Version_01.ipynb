{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFnvXugQNXDujOZT3Qwu9s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayeshamaqsood6100-lab/My-Projects-/blob/main/Version_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0mD7QBy8Rva"
      },
      "outputs": [],
      "source": [
        "# @title ðŸš€ Meta Sapiens: HIGH QUALITY (1B Models)\n",
        "# ============================================================================\n",
        "# META SAPIENS FOR PSL - HIGH QUALITY EDITION\n",
        "# ============================================================================\n",
        "# Uses the larger 1B models for maximum accuracy:\n",
        "# - POSE 1B: Best keypoint accuracy\n",
        "# - SEG 1B: Best segmentation quality\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 0: INSTALL DEPENDENCIES\n",
        "# ============================================================================\n",
        "print(\"ðŸ”§ PHASE 0: INSTALLING DEPENDENCIES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "print(\"ðŸ“¦ Installing dependencies...\")\n",
        "install(\"torch\")\n",
        "install(\"torchvision\")\n",
        "install(\"opencv-python\")\n",
        "install(\"tqdm\")\n",
        "install(\"huggingface_hub\")\n",
        "\n",
        "print(\"âœ… Dependencies installed!\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 1: MOUNT GOOGLE DRIVE\n",
        "# ============================================================================\n",
        "print(\"ðŸš€ PHASE 1: MOUNTING GOOGLE DRIVE\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "    print(\"âœ… Google Drive mounted!\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"âš ï¸ Not running in Colab.\")\n",
        "\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 2: DOWNLOAD HIGH-QUALITY MODELS (1B)\n",
        "# ============================================================================\n",
        "print(\"ðŸš€ PHASE 2: DOWNLOADING 1B MODELS (Higher Quality)\")\n",
        "print(\"-\" * 60)\n",
        "print(\"âš ï¸ 1B models are larger (~4GB each). This may take a few minutes...\")\n",
        "print()\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "MODEL_DIR = \"/content/sapiens_models\" if IN_COLAB else \"./sapiens_models\"\n",
        "\n",
        "# Download POSE 1B model (highest accuracy)\n",
        "print(\"ðŸ“¦ Downloading Sapiens POSE 1B Model...\")\n",
        "POSE_MODEL_PATH = hf_hub_download(\n",
        "    repo_id=\"facebook/sapiens-pose-1b-torchscript\",\n",
        "    filename=\"sapiens_1b_goliath_best_goliath_AP_639_torchscript.pt2\",\n",
        "    local_dir=MODEL_DIR\n",
        ")\n",
        "print(\"âœ… Pose 1B model ready!\")\n",
        "\n",
        "# Download SEG 1B model (highest quality)\n",
        "print(\"ðŸ“¦ Downloading Sapiens SEG 1B Model...\")\n",
        "SEG_MODEL_PATH = hf_hub_download(\n",
        "    repo_id=\"facebook/sapiens-seg-1b-torchscript\",\n",
        "    filename=\"sapiens_1b_goliath_best_goliath_mIoU_7994_epoch_151_torchscript.pt2\",\n",
        "    local_dir=MODEL_DIR\n",
        ")\n",
        "print(\"âœ… Segmentation 1B model ready!\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# BODY PART CLASSES & COLORS (28 classes)\n",
        "# ============================================================================\n",
        "\n",
        "BODY_PARTS = [\n",
        "    \"Background\", \"Head\", \"Neck\", \"Torso\",\n",
        "    \"Left_Upper_Arm\", \"Right_Upper_Arm\", \"Left_Lower_Arm\", \"Right_Lower_Arm\",\n",
        "    \"Left_Hand\", \"Right_Hand\", \"Left_Upper_Leg\", \"Right_Upper_Leg\",\n",
        "    \"Left_Lower_Leg\", \"Right_Lower_Leg\", \"Left_Foot\", \"Right_Foot\",\n",
        "    \"Hair\", \"Face\", \"Teeth\", \"Tongue\", \"Upper_Lip\", \"Lower_Lip\",\n",
        "    \"Left_Eyebrow\", \"Right_Eyebrow\", \"Left_Eye\", \"Right_Eye\", \"Nose\", \"Ears\"\n",
        "]\n",
        "\n",
        "# Vibrant colors matching Meta's demo\n",
        "BODY_PART_COLORS = np.array([\n",
        "    [0, 0, 0],         # Background\n",
        "    [255, 220, 200],   # Head\n",
        "    [255, 200, 170],   # Neck\n",
        "    [100, 200, 100],   # Torso - Green\n",
        "    [50, 255, 50],     # Left_Upper_Arm - Green\n",
        "    [255, 165, 0],     # Right_Upper_Arm - Orange\n",
        "    [0, 255, 128],     # Left_Lower_Arm\n",
        "    [255, 140, 0],     # Right_Lower_Arm\n",
        "    [0, 255, 255],     # Left_Hand - Cyan\n",
        "    [255, 100, 100],   # Right_Hand - Red\n",
        "    [100, 100, 255],   # Left_Upper_Leg - Blue\n",
        "    [255, 100, 255],   # Right_Upper_Leg - Purple\n",
        "    [50, 50, 200],     # Left_Lower_Leg\n",
        "    [200, 50, 200],    # Right_Lower_Leg\n",
        "    [0, 200, 200],     # Left_Foot - Teal\n",
        "    [200, 200, 0],     # Right_Foot - Yellow\n",
        "    [139, 90, 43],     # Hair - Brown\n",
        "    [255, 210, 180],   # Face - Skin\n",
        "    [255, 255, 255],   # Teeth - White\n",
        "    [255, 100, 150],   # Tongue - Pink\n",
        "    [255, 150, 150],   # Upper_Lip\n",
        "    [255, 120, 120],   # Lower_Lip\n",
        "    [160, 110, 60],    # Left_Eyebrow\n",
        "    [160, 110, 60],    # Right_Eyebrow\n",
        "    [100, 160, 220],   # Left_Eye\n",
        "    [100, 160, 220],   # Right_Eye\n",
        "    [255, 200, 160],   # Nose\n",
        "    [200, 160, 110],   # Ears\n",
        "], dtype=np.uint8)\n",
        "\n",
        "# ============================================================================\n",
        "# SKELETON DEFINITIONS\n",
        "# ============================================================================\n",
        "\n",
        "GOLIATH_KEYPOINTS = [\n",
        "    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
        "    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
        "    'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
        "    'left_ankle', 'right_ankle', 'left_big_toe', 'left_small_toe',\n",
        "    'left_heel', 'right_big_toe', 'right_small_toe', 'right_heel',\n",
        "    'right_thumb4', 'right_thumb3', 'right_thumb2', 'right_thumb_third_joint',\n",
        "    'right_forefinger4', 'right_forefinger3', 'right_forefinger2', 'right_forefinger_third_joint',\n",
        "    'right_middle_finger4', 'right_middle_finger3', 'right_middle_finger2', 'right_middle_finger_third_joint',\n",
        "    'right_ring_finger4', 'right_ring_finger3', 'right_ring_finger2', 'right_ring_finger_third_joint',\n",
        "    'right_pinky_finger4', 'right_pinky_finger3', 'right_pinky_finger2', 'right_pinky_finger_third_joint',\n",
        "    'right_wrist',\n",
        "    'left_thumb4', 'left_thumb3', 'left_thumb2', 'left_thumb_third_joint',\n",
        "    'left_forefinger4', 'left_forefinger3', 'left_forefinger2', 'left_forefinger_third_joint',\n",
        "    'left_middle_finger4', 'left_middle_finger3', 'left_middle_finger2', 'left_middle_finger_third_joint',\n",
        "    'left_ring_finger4', 'left_ring_finger3', 'left_ring_finger2', 'left_ring_finger_third_joint',\n",
        "    'left_pinky_finger4', 'left_pinky_finger3', 'left_pinky_finger2', 'left_pinky_finger_third_joint',\n",
        "    'left_wrist', 'left_olecranon', 'right_olecranon',\n",
        "    'left_cubital_fossa', 'right_cubital_fossa', 'left_acromion', 'right_acromion', 'neck',\n",
        "]\n",
        "for i in range(len(GOLIATH_KEYPOINTS), 308):\n",
        "    GOLIATH_KEYPOINTS.append(f'face_kp_{i}')\n",
        "\n",
        "SKELETON = [\n",
        "    # Body core (blue)\n",
        "    ('left_shoulder', 'right_shoulder', (51, 153, 255)),\n",
        "    ('left_hip', 'right_hip', (51, 153, 255)),\n",
        "    ('left_shoulder', 'left_hip', (51, 153, 255)),\n",
        "    ('right_shoulder', 'right_hip', (51, 153, 255)),\n",
        "    ('neck', 'left_shoulder', (51, 153, 255)),\n",
        "    ('neck', 'right_shoulder', (51, 153, 255)),\n",
        "    # Left side (green)\n",
        "    ('left_shoulder', 'left_elbow', (0, 255, 0)),\n",
        "    ('left_elbow', 'left_wrist', (0, 255, 0)),\n",
        "    ('left_hip', 'left_knee', (0, 255, 0)),\n",
        "    ('left_knee', 'left_ankle', (0, 255, 0)),\n",
        "    ('left_ankle', 'left_big_toe', (0, 255, 0)),\n",
        "    ('left_ankle', 'left_heel', (0, 255, 0)),\n",
        "    # Right side (orange)\n",
        "    ('right_shoulder', 'right_elbow', (255, 128, 0)),\n",
        "    ('right_elbow', 'right_wrist', (255, 128, 0)),\n",
        "    ('right_hip', 'right_knee', (255, 128, 0)),\n",
        "    ('right_knee', 'right_ankle', (255, 128, 0)),\n",
        "    ('right_ankle', 'right_big_toe', (255, 128, 0)),\n",
        "    ('right_ankle', 'right_heel', (255, 128, 0)),\n",
        "    # Face (blue)\n",
        "    ('nose', 'left_eye', (51, 153, 255)),\n",
        "    ('nose', 'right_eye', (51, 153, 255)),\n",
        "    ('left_eye', 'left_ear', (51, 153, 255)),\n",
        "    ('right_eye', 'right_ear', (51, 153, 255)),\n",
        "    # Left hand fingers\n",
        "    ('left_wrist', 'left_thumb_third_joint', (255, 128, 0)),\n",
        "    ('left_thumb_third_joint', 'left_thumb2', (255, 128, 0)),\n",
        "    ('left_thumb2', 'left_thumb3', (255, 128, 0)),\n",
        "    ('left_thumb3', 'left_thumb4', (255, 128, 0)),\n",
        "    ('left_wrist', 'left_forefinger_third_joint', (255, 153, 255)),\n",
        "    ('left_forefinger_third_joint', 'left_forefinger2', (255, 153, 255)),\n",
        "    ('left_forefinger2', 'left_forefinger3', (255, 153, 255)),\n",
        "    ('left_forefinger3', 'left_forefinger4', (255, 153, 255)),\n",
        "    ('left_wrist', 'left_middle_finger_third_joint', (102, 178, 255)),\n",
        "    ('left_middle_finger_third_joint', 'left_middle_finger2', (102, 178, 255)),\n",
        "    ('left_middle_finger2', 'left_middle_finger3', (102, 178, 255)),\n",
        "    ('left_middle_finger3', 'left_middle_finger4', (102, 178, 255)),\n",
        "    ('left_wrist', 'left_ring_finger_third_joint', (255, 51, 51)),\n",
        "    ('left_ring_finger_third_joint', 'left_ring_finger2', (255, 51, 51)),\n",
        "    ('left_ring_finger2', 'left_ring_finger3', (255, 51, 51)),\n",
        "    ('left_ring_finger3', 'left_ring_finger4', (255, 51, 51)),\n",
        "    ('left_wrist', 'left_pinky_finger_third_joint', (0, 255, 0)),\n",
        "    ('left_pinky_finger_third_joint', 'left_pinky_finger2', (0, 255, 0)),\n",
        "    ('left_pinky_finger2', 'left_pinky_finger3', (0, 255, 0)),\n",
        "    ('left_pinky_finger3', 'left_pinky_finger4', (0, 255, 0)),\n",
        "    # Right hand fingers\n",
        "    ('right_wrist', 'right_thumb_third_joint', (255, 128, 0)),\n",
        "    ('right_thumb_third_joint', 'right_thumb2', (255, 128, 0)),\n",
        "    ('right_thumb2', 'right_thumb3', (255, 128, 0)),\n",
        "    ('right_thumb3', 'right_thumb4', (255, 128, 0)),\n",
        "    ('right_wrist', 'right_forefinger_third_joint', (255, 153, 255)),\n",
        "    ('right_forefinger_third_joint', 'right_forefinger2', (255, 153, 255)),\n",
        "    ('right_forefinger2', 'right_forefinger3', (255, 153, 255)),\n",
        "    ('right_forefinger3', 'right_forefinger4', (255, 153, 255)),\n",
        "    ('right_wrist', 'right_middle_finger_third_joint', (102, 178, 255)),\n",
        "    ('right_middle_finger_third_joint', 'right_middle_finger2', (102, 178, 255)),\n",
        "    ('right_middle_finger2', 'right_middle_finger3', (102, 178, 255)),\n",
        "    ('right_middle_finger3', 'right_middle_finger4', (102, 178, 255)),\n",
        "    ('right_wrist', 'right_ring_finger_third_joint', (255, 51, 51)),\n",
        "    ('right_ring_finger_third_joint', 'right_ring_finger2', (255, 51, 51)),\n",
        "    ('right_ring_finger2', 'right_ring_finger3', (255, 51, 51)),\n",
        "    ('right_ring_finger3', 'right_ring_finger4', (255, 51, 51)),\n",
        "    ('right_wrist', 'right_pinky_finger_third_joint', (0, 255, 0)),\n",
        "    ('right_pinky_finger_third_joint', 'right_pinky_finger2', (0, 255, 0)),\n",
        "    ('right_pinky_finger2', 'right_pinky_finger3', (0, 255, 0)),\n",
        "    ('right_pinky_finger3', 'right_pinky_finger4', (0, 255, 0)),\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 3: RUN INFERENCE\n",
        "# ============================================================================\n",
        "print(\"ðŸš€ PHASE 3: RUNNING HIGH-QUALITY INFERENCE\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "VIDEO_FILENAME = \"Bandbaja.mp4\"\n",
        "BASE_PATH = \"/content/drive/MyDrive\" if IN_COLAB else \".\"\n",
        "INPUT_VIDEO = os.path.join(BASE_PATH, VIDEO_FILENAME)\n",
        "OUTPUT_POSE = os.path.join(BASE_PATH, f\"HQ_POSE_{VIDEO_FILENAME}\")\n",
        "OUTPUT_SEG = os.path.join(BASE_PATH, f\"HQ_SEG_{VIDEO_FILENAME}\")\n",
        "OUTPUT_COMBINED = os.path.join(BASE_PATH, f\"HQ_COMBINED_{VIDEO_FILENAME}\")\n",
        "OUTPUT_JSON = os.path.join(BASE_PATH, f\"HQ_Keypoints_{VIDEO_FILENAME}.json\")\n",
        "\n",
        "if not os.path.exists(INPUT_VIDEO):\n",
        "    print(f\"âŒ Video not found: {INPUT_VIDEO}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"ðŸ“¹ Input: {INPUT_VIDEO}\")\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "print(f\"ðŸ“Š {width}x{height} @ {fps:.1f} FPS, {total_frames} frames\")\n",
        "\n",
        "ret, test_frame = cap.read()\n",
        "if not ret:\n",
        "    print(\"âš ï¸ Converting video...\")\n",
        "    cap.release()\n",
        "    CONV = \"/content/conv.mp4\" if IN_COLAB else \"./conv.mp4\"\n",
        "    subprocess.run(f'ffmpeg -y -i \"{INPUT_VIDEO}\" -c:v libx264 \"{CONV}\"', shell=True, capture_output=True)\n",
        "    INPUT_VIDEO = CONV\n",
        "    cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "# Load models\n",
        "print(\"ðŸ“¦ Loading 1B models (may take a moment)...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "pose_model = torch.jit.load(POSE_MODEL_PATH, map_location=device).eval()\n",
        "seg_model = torch.jit.load(SEG_MODEL_PATH, map_location=device).eval()\n",
        "print(\"âœ… Models loaded!\")\n",
        "\n",
        "# High quality video writers (use libx264 via ffmpeg pipe for better quality)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_pose = cv2.VideoWriter(OUTPUT_POSE, fourcc, fps, (width, height))\n",
        "out_seg = cv2.VideoWriter(OUTPUT_SEG, fourcc, fps, (width, height))\n",
        "out_combined = cv2.VideoWriter(OUTPUT_COMBINED, fourcc, fps, (width * 2, height))\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess(img):\n",
        "    img = cv2.resize(img, (768, 1024))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
        "    return torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0).float()\n",
        "\n",
        "def get_keypoints(heatmaps, w, h):\n",
        "    kps = {}\n",
        "    for i, name in enumerate(GOLIATH_KEYPOINTS):\n",
        "        if i >= heatmaps.shape[0]:\n",
        "            break\n",
        "        hm = heatmaps[i]\n",
        "        idx = np.argmax(hm)\n",
        "        y, x = np.unravel_index(idx, hm.shape)\n",
        "        conf = float(hm[y, x])\n",
        "        kps[name] = {'x': x * w / hm.shape[1], 'y': y * h / hm.shape[0], 'conf': conf}\n",
        "    return kps\n",
        "\n",
        "def draw_pose_hq(frame, kps, conf_thresh=0.2):\n",
        "    h, w = frame.shape[:2]\n",
        "    # Thicker lines for high quality\n",
        "    line_thickness = max(2, int(min(w, h) / 300))\n",
        "    point_radius = max(3, int(min(w, h) / 200))\n",
        "\n",
        "    # Draw skeleton\n",
        "    for start, end, color in SKELETON:\n",
        "        if start in kps and end in kps:\n",
        "            k1, k2 = kps[start], kps[end]\n",
        "            if k1['conf'] > conf_thresh and k2['conf'] > conf_thresh:\n",
        "                pt1 = (int(k1['x']), int(k1['y']))\n",
        "                pt2 = (int(k2['x']), int(k2['y']))\n",
        "                if 0 <= pt1[0] < w and 0 <= pt1[1] < h and 0 <= pt2[0] < w and 0 <= pt2[1] < h:\n",
        "                    cv2.line(frame, pt1, pt2, color, line_thickness, cv2.LINE_AA)\n",
        "\n",
        "    # Draw keypoints\n",
        "    for name, kp in kps.items():\n",
        "        if kp['conf'] > conf_thresh:\n",
        "            x, y = int(kp['x']), int(kp['y'])\n",
        "            if 0 <= x < w and 0 <= y < h:\n",
        "                # Color based on side\n",
        "                if 'left' in name:\n",
        "                    color = (0, 255, 0)\n",
        "                elif 'right' in name:\n",
        "                    color = (255, 128, 0)\n",
        "                else:\n",
        "                    color = (51, 153, 255)\n",
        "                cv2.circle(frame, (x, y), point_radius, color, -1, cv2.LINE_AA)\n",
        "                cv2.circle(frame, (x, y), point_radius, (255, 255, 255), 1, cv2.LINE_AA)  # White outline\n",
        "    return frame\n",
        "\n",
        "def draw_seg_hq(seg_map, w, h, original_frame, blend_alpha=0.7):\n",
        "    \"\"\"High quality segmentation with blending onto original frame.\"\"\"\n",
        "    # Create colored segmentation\n",
        "    seg_colored = BODY_PART_COLORS[seg_map]\n",
        "    seg_colored = cv2.resize(seg_colored, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Blend with original frame for better quality\n",
        "    mask = (seg_map != 0).astype(np.uint8)\n",
        "    mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "    mask = np.expand_dims(mask, axis=2)\n",
        "\n",
        "    blended = (seg_colored * blend_alpha + original_frame * (1 - blend_alpha)).astype(np.uint8)\n",
        "    result = np.where(mask > 0, blended, original_frame)\n",
        "    return result.astype(np.uint8)\n",
        "\n",
        "# Process\n",
        "all_results = []\n",
        "print()\n",
        "print(\"ðŸŽ¬ Processing with HIGH QUALITY 1B models...\")\n",
        "print(\"   (This will be slower but much more accurate)\")\n",
        "print()\n",
        "\n",
        "with tqdm(total=total_frames, desc=\"Frames\") as pbar:\n",
        "    frame_idx = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        tensor = preprocess(frame).to(device)\n",
        "\n",
        "        # POSE\n",
        "        with torch.no_grad():\n",
        "            pose_out = pose_model(tensor)\n",
        "        heatmaps = (pose_out[0] if isinstance(pose_out, tuple) else pose_out)[0].cpu().numpy()\n",
        "        kps = get_keypoints(heatmaps, width, height)\n",
        "\n",
        "        # SEG\n",
        "        with torch.no_grad():\n",
        "            seg_out = seg_model(tensor)\n",
        "        seg_logits = (seg_out[0] if isinstance(seg_out, tuple) else seg_out)[0].cpu().numpy()\n",
        "        seg_map = np.argmax(seg_logits, axis=0)\n",
        "\n",
        "        # Draw HQ outputs\n",
        "        pose_frame = draw_pose_hq(frame.copy(), kps)\n",
        "        seg_frame = draw_seg_hq(seg_map, width, height, frame.copy())\n",
        "        combined = np.hstack([pose_frame, seg_frame])\n",
        "\n",
        "        out_pose.write(pose_frame)\n",
        "        out_seg.write(seg_frame)\n",
        "        out_combined.write(combined)\n",
        "\n",
        "        all_results.append({\n",
        "            \"frame\": frame_idx,\n",
        "            \"timestamp\": frame_idx / fps,\n",
        "            \"keypoints\": {k: {\"x\": v[\"x\"], \"y\": v[\"y\"], \"confidence\": v[\"conf\"]} for k, v in kps.items()}\n",
        "        })\n",
        "\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "out_pose.release()\n",
        "out_seg.release()\n",
        "out_combined.release()\n",
        "\n",
        "# Save JSON\n",
        "with open(OUTPUT_JSON, 'w') as f:\n",
        "    json.dump({\n",
        "        \"video_info\": {\"filename\": VIDEO_FILENAME, \"width\": width, \"height\": height, \"fps\": fps, \"frames\": frame_idx},\n",
        "        \"models\": {\"pose\": \"Sapiens 1B (308 keypoints)\", \"segmentation\": \"Sapiens 1B (28 body parts)\"},\n",
        "        \"body_parts\": BODY_PARTS,\n",
        "        \"frames\": all_results\n",
        "    }, f, indent=2)\n",
        "\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ…âœ…âœ… HIGH QUALITY PROCESSING COMPLETE! âœ…âœ…âœ…\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"ðŸ“¹ OUTPUTS:\")\n",
        "print(f\"   POSE: {OUTPUT_POSE}\")\n",
        "print(f\"   SEG: {OUTPUT_SEG}\")\n",
        "print(f\"   COMBINED: {OUTPUT_COMBINED}\")\n",
        "print(f\"   JSON: {OUTPUT_JSON}\")"
      ]
    }
  ]
}