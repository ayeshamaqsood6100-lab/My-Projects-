# @title üåà Sapiens SURFACE NORMALS (Standalone)
# ============================================================================
# Creates surface normal video with human-only masking (black background)
# Requires segmentation masks OR will create them on-the-fly
# ============================================================================

import os, sys, subprocess, cv2, numpy as np, gc
from tqdm import tqdm

print("üîß Installing...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "torch", "huggingface_hub", "opencv-python", "tqdm"])

import torch
from huggingface_hub import hf_hub_download

# ============================================================================
# SETUP
# ============================================================================
try:
    from google.colab import drive
    if not os.path.exists('/content/drive'):
        drive.mount('/content/drive')
    print("‚úÖ Google Drive mounted!")
    IN_COLAB = True
except:
    IN_COLAB = False

# CONFIG
VIDEO_FILENAME = "Brother.mp4"
BASE_PATH = "/content/drive/MyDrive/ConnectHearTestVideos" if IN_COLAB else "."
MODEL_DIR = "/content/sapiens_models" if IN_COLAB else "./sapiens_models"
os.makedirs(MODEL_DIR, exist_ok=True)

RAW_INPUT = os.path.join(BASE_PATH, VIDEO_FILENAME)
CLEAN_INPUT = "/content/cleaned_input.mp4"
OUTPUT_NORMAL = os.path.join(BASE_PATH, f"NORMAL_{VIDEO_FILENAME}")

# Check input
print(f"\nüîç Input: {RAW_INPUT}")
if not os.path.exists(RAW_INPUT):
    print(f"‚ùå ERROR: File not found!")
    sys.exit(1)

# Repair video
print("üîß Preparing video...")
subprocess.run(f'ffmpeg -y -loglevel error -i "{RAW_INPUT}" -c:v libx264 -preset fast -crf 22 "{CLEAN_INPUT}"', shell=True)

# Get video info
cap = cv2.VideoCapture(CLEAN_INPUT)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
fps = cap.get(cv2.CAP_PROP_FPS) or 30
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
width, height = (width // 2) * 2, (height // 2) * 2
cap.release()

print(f"   Video: {width}x{height}, {total_frames} frames, {fps:.1f} fps")

# ============================================================================
# DOWNLOAD MODELS
# ============================================================================
print("\nüì¶ Downloading models...")

# Segmentation (for masks)
SEG_MODEL_PATH = hf_hub_download(
    repo_id="facebook/sapiens-seg-1b-torchscript",
    filename="sapiens_1b_goliath_best_goliath_mIoU_7994_epoch_151_torchscript.pt2",
    local_dir=MODEL_DIR
)

# Surface Normals
NORMAL_MODEL_PATH = hf_hub_download(
    repo_id="facebook/sapiens-normal-1b-torchscript",
    filename="sapiens_1b_normal_render_people_epoch_115_torchscript.pt2",
    local_dir=MODEL_DIR
)

print("‚úÖ Models downloaded")

# ============================================================================
# LOAD MODELS
# ============================================================================
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"\nüéÆ Device: {device}")

print("üîÑ Loading Segmentation (for masks)...")
seg_model = torch.jit.load(SEG_MODEL_PATH, map_location=device).eval()

print("üîÑ Loading Surface Normals...")
normal_model = torch.jit.load(NORMAL_MODEL_PATH, map_location=device).eval()

print("‚úÖ All models loaded")

# ============================================================================
# PREPROCESSING
# ============================================================================
def preprocess(img):
    img = cv2.resize(img, (768, 1024))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
    return torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0).float()

# ============================================================================
# PROCESS VIDEO
# ============================================================================
print("\nüèÉ Processing...")

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter("/content/temp_normal.mp4", fourcc, fps, (width, height))

cap = cv2.VideoCapture(CLEAN_INPUT)

with tqdm(total=total_frames, desc="Normals") as pbar:
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame = cv2.resize(frame, (width, height))
        tensor = preprocess(frame).to(device)
        
        # Get segmentation mask (SMOOTH edges to avoid blocky artifacts)
        with torch.no_grad():
            seg_out = seg_model(tensor)
        seg_logits = (seg_out[0] if isinstance(seg_out, tuple) else seg_out)[0].cpu().numpy()
        seg_map = np.argmax(seg_logits, axis=0)
        
        # Smooth mask resizing (INTER_LINEAR instead of NEAREST)
        mask_lowres = (seg_map > 0).astype(np.uint8) * 255
        mask = cv2.resize(mask_lowres, (width, height), interpolation=cv2.INTER_LINEAR)
        mask = (mask > 127).astype(np.uint8) * 255  # Threshold back to binary
        mask = cv2.GaussianBlur(mask, (11, 11), 0)  # INCREASED: Smoother edges
        
        # Get surface normals
        with torch.no_grad():
            normal_out = normal_model(tensor)
        normal = (normal_out[0] if isinstance(normal_out, tuple) else normal_out)[0].cpu().numpy()
        
        # Convert (3, H, W) -> (H, W, 3)
        normal = normal.transpose(1, 2, 0)
        normal = cv2.resize(normal, (width, height), interpolation=cv2.INTER_LINEAR)
        
        # Normalize to [0, 255]
        normal_rgb = ((normal + 1) / 2 * 255).astype(np.uint8)
        normal_bgr = cv2.cvtColor(normal_rgb, cv2.COLOR_RGB2BGR)
        
        # Black background
        normal_final = np.where(mask[:,:,None] > 0, normal_bgr, 0)
        
        out.write(normal_final)
        pbar.update(1)

cap.release()
out.release()

# Cleanup models
del seg_model, normal_model
gc.collect()
if device == 'cuda':
    torch.cuda.empty_cache()

# ============================================================================
# FINALIZE
# ============================================================================
print("\nüîÑ Encoding...")
subprocess.run(f'ffmpeg -y -loglevel error -i "/content/temp_normal.mp4" -c:v libx264 -pix_fmt yuv420p "{OUTPUT_NORMAL}"', shell=True)

# Cleanup
if os.path.exists("/content/temp_normal.mp4"):
    os.remove("/content/temp_normal.mp4")
if os.path.exists(CLEAN_INPUT):
    os.remove(CLEAN_INPUT)

print("\n" + "="*60)
print("‚úÖ SUCCESS!")
print("="*60)
print(f"\nüìÅ Output: {OUTPUT_NORMAL}")
print("\n‚úÖ Features:")
print("   ‚Ä¢ Surface normals (RGB = XYZ direction)")
print("   ‚Ä¢ Human-only (black background)")
print("   ‚Ä¢ Uses Sapiens 1B (best quality)")
