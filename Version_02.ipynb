{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcbkm9Zcase3RUcKQQpwoo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayeshamaqsood6100-lab/My-Projects-/blob/main/Version_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC9BbtxZ8C5J"
      },
      "outputs": [],
      "source": [
        "# @title üöÄ Meta Sapiens: GOLIATH 1B - v9 (Repair & Diagnostic)\n",
        "# ============================================================================\n",
        "# META SAPIENS 1B - GOLIATH EDITION v9\n",
        "# ============================================================================\n",
        "# DIAGNOSTIC MODE:\n",
        "# 1. Forces FFmpeg \"Repair\" on input video to ensure readability.\n",
        "# 2. Prints frame progress explicitly.\n",
        "# 3. Uses Sequential processing to save RAM.\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 0: INSTALL DEPENDENCIES\n",
        "# ============================================================================\n",
        "print(\"üîß PHASE 0: INSTALLING DEPENDENCIES\")\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "install(\"torch\")\n",
        "install(\"torchvision\")\n",
        "install(\"opencv-python\")\n",
        "install(\"tqdm\")\n",
        "install(\"huggingface_hub\")\n",
        "print(\"‚úÖ Dependencies installed!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# PHASE 1: SETUP & DOWNLOAD MODELS\n",
        "# ============================================================================\n",
        "print(\"üöÄ PHASE 1: SETUP\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úÖ Google Drive mounted!\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚ö†Ô∏è Not running in Colab.\")\n",
        "\n",
        "MODEL_DIR = \"/content/sapiens_models\" if IN_COLAB else \"./sapiens_models\"\n",
        "\n",
        "print(\"\\nüì¶ Downloading Models (Goliath 1B)...\")\n",
        "POSE_MODEL_PATH = hf_hub_download(repo_id=\"facebook/sapiens-pose-1b-torchscript\", filename=\"sapiens_1b_goliath_best_goliath_AP_639_torchscript.pt2\", local_dir=MODEL_DIR)\n",
        "SEG_MODEL_PATH = hf_hub_download(repo_id=\"facebook/sapiens-seg-1b-torchscript\", filename=\"sapiens_1b_goliath_best_goliath_mIoU_7994_epoch_151_torchscript.pt2\", local_dir=MODEL_DIR)\n",
        "print(\"‚úÖ Models Ready!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION & UTILS\n",
        "# ============================================================================\n",
        "VIDEO_FILENAME = \"Bandbaja.mp4\"  # <--- MAKE SURE THIS MATCHES YOUR FILE\n",
        "BASE_PATH = \"/content/drive/MyDrive\" if IN_COLAB else \".\"\n",
        "RAW_INPUT = os.path.join(BASE_PATH, VIDEO_FILENAME)\n",
        "\n",
        "# We will create a \"Cleaned\" version of the input first\n",
        "CLEAN_INPUT = \"/content/cleaned_input.mp4\" if IN_COLAB else \"./cleaned_input.mp4\"\n",
        "\n",
        "# Outputs\n",
        "OUTPUT_POSE_AVI = os.path.join(BASE_PATH, \"temp_pose.avi\")\n",
        "OUTPUT_SEG_AVI = os.path.join(BASE_PATH, \"temp_seg.avi\")\n",
        "OUTPUT_COMBINED_AVI = os.path.join(BASE_PATH, \"temp_combined.avi\")\n",
        "OUTPUT_FINAL = os.path.join(BASE_PATH, f\"GOLIATH_v9_{VIDEO_FILENAME}\")\n",
        "\n",
        "# --- REPAIR VIDEO FUNCTION ---\n",
        "print(f\"üîç Checking Input: {RAW_INPUT}\")\n",
        "if not os.path.exists(RAW_INPUT):\n",
        "    print(f\"‚ùå ERROR: File not found at {RAW_INPUT}\")\n",
        "    print(\"   Please check the filename in your Google Drive.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"üîß Repairing video with FFmpeg to ensure readability...\")\n",
        "# Converts to standard H.264 MP4. This fixes 99% of \"OpenCV read fail\" errors.\n",
        "subprocess.run(f'ffmpeg -y -loglevel error -i \"{RAW_INPUT}\" -c:v libx264 -preset fast -crf 23 -pix_fmt yuv420p \"{CLEAN_INPUT}\"', shell=True)\n",
        "\n",
        "if not os.path.exists(CLEAN_INPUT):\n",
        "    print(\"‚ùå Critical Error: FFmpeg failed to process video.\")\n",
        "    sys.exit(1)\n",
        "else:\n",
        "    print(\"‚úÖ Video Repaired and Ready.\")\n",
        "\n",
        "# ============================================================================\n",
        "# LOGIC & DRAWING\n",
        "# ============================================================================\n",
        "GOLIATH_KEYPOINTS = [\n",
        "    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
        "    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
        "    'left_hip', 'right_hip', 'left_knee', 'right_knee',\n",
        "    'left_ankle', 'right_ankle', 'left_big_toe', 'left_small_toe',\n",
        "    'left_heel', 'right_big_toe', 'right_small_toe', 'right_heel',\n",
        "    'right_thumb4', 'right_thumb3', 'right_thumb2', 'right_thumb_third_joint',\n",
        "    'right_forefinger4', 'right_forefinger3', 'right_forefinger2', 'right_forefinger_third_joint',\n",
        "    'right_middle_finger4', 'right_middle_finger3', 'right_middle_finger2', 'right_middle_finger_third_joint',\n",
        "    'right_ring_finger4', 'right_ring_finger3', 'right_ring_finger2', 'right_ring_finger_third_joint',\n",
        "    'right_pinky_finger4', 'right_pinky_finger3', 'right_pinky_finger2', 'right_pinky_finger_third_joint',\n",
        "    'right_wrist',\n",
        "    'left_thumb4', 'left_thumb3', 'left_thumb2', 'left_thumb_third_joint',\n",
        "    'left_forefinger4', 'left_forefinger3', 'left_forefinger2', 'left_forefinger_third_joint',\n",
        "    'left_middle_finger4', 'left_middle_finger3', 'left_middle_finger2', 'left_middle_finger_third_joint',\n",
        "    'left_ring_finger4', 'left_ring_finger3', 'left_ring_finger2', 'left_ring_finger_third_joint',\n",
        "    'left_pinky_finger4', 'left_pinky_finger3', 'left_pinky_finger2', 'left_pinky_finger_third_joint',\n",
        "    'left_wrist', 'left_olecranon', 'right_olecranon',\n",
        "    'left_cubital_fossa', 'right_cubital_fossa', 'left_acromion', 'right_acromion', 'neck',\n",
        "]\n",
        "for i in range(len(GOLIATH_KEYPOINTS), 308): GOLIATH_KEYPOINTS.append(f'face_kp_{i}')\n",
        "\n",
        "BODY_PART_COLORS = np.array([\n",
        "    [0,0,0], [255,220,200], [255,200,170], [100,200,100], [50,255,50], [255,165,0],\n",
        "    [0,255,128], [255,140,0], [0,255,255], [255,100,100], [100,100,255], [255,100,255],\n",
        "    [50,50,200], [200,50,200], [0,200,200], [200,200,0], [139,90,43], [255,210,180],\n",
        "    [255,255,255], [255,100,150], [255,150,150], [255,120,120], [160,110,60], [160,110,60],\n",
        "    [100,160,220], [100,160,220], [255,200,160], [200,160,110]], dtype=np.uint8)\n",
        "\n",
        "C_ORANGE = (255, 165, 0); C_BLUE = (51, 153, 255); C_GREEN = (0, 255, 0); C_FACE_KP = (255, 255, 255)\n",
        "SKELETON = [\n",
        "    ('left_shoulder', 'right_shoulder', C_ORANGE), ('left_hip', 'right_hip', C_ORANGE),\n",
        "    ('left_shoulder', 'left_hip', C_ORANGE), ('right_shoulder', 'right_hip', C_ORANGE),\n",
        "    ('neck', 'left_shoulder', C_ORANGE), ('neck', 'right_shoulder', C_ORANGE),\n",
        "    ('left_shoulder', 'left_elbow', C_GREEN), ('left_elbow', 'left_wrist', C_GREEN),\n",
        "    ('left_hip', 'left_knee', C_GREEN), ('left_knee', 'left_ankle', C_GREEN),\n",
        "    ('left_ankle', 'left_big_toe', C_GREEN), ('left_ankle', 'left_heel', C_GREEN),\n",
        "    ('right_shoulder', 'right_elbow', C_BLUE), ('right_elbow', 'right_wrist', C_BLUE),\n",
        "    ('right_hip', 'right_knee', C_BLUE), ('right_knee', 'right_ankle', C_BLUE),\n",
        "    ('right_ankle', 'right_big_toe', C_BLUE), ('right_ankle', 'right_heel', C_BLUE),\n",
        "    ('left_wrist', 'left_thumb_third_joint', C_GREEN), ('right_wrist', 'right_thumb_third_joint', C_BLUE)\n",
        "]\n",
        "for side, color in [('left', C_GREEN), ('right', C_BLUE)]:\n",
        "    for finger in ['thumb', 'forefinger', 'middle_finger', 'ring_finger', 'pinky_finger']:\n",
        "        base = f'{side}_{finger}_third_joint' if finger != 'thumb' else f'{side}_thumb_third_joint'\n",
        "        SKELETON.append((f'{side}_wrist', base, color))\n",
        "\n",
        "def preprocess(img):\n",
        "    img = cv2.resize(img, (768, 1024))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
        "    return torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0).float()\n",
        "\n",
        "def get_keypoints(heatmaps, w, h):\n",
        "    kps = {}\n",
        "    for i, name in enumerate(GOLIATH_KEYPOINTS):\n",
        "        if i >= heatmaps.shape[0]: break\n",
        "        hm = heatmaps[i]; idx = np.argmax(hm)\n",
        "        y, x = np.unravel_index(idx, hm.shape)\n",
        "        kps[name] = {'x': x * w / hm.shape[1], 'y': y * h / hm.shape[0], 'conf': float(hm[y, x])}\n",
        "    return kps\n",
        "\n",
        "def draw_pose_hq(frame, kps, conf_thresh=0.3):\n",
        "    h, w = frame.shape[:2]\n",
        "    line_thick = max(1, int(min(w, h) / 600))\n",
        "    face_rad = 1\n",
        "    # Lines\n",
        "    for start, end, color in SKELETON:\n",
        "        if start in kps and end in kps:\n",
        "            k1, k2 = kps[start], kps[end]\n",
        "            if k1['conf'] > conf_thresh and k2['conf'] > conf_thresh:\n",
        "                cv2.line(frame, (int(k1['x']), int(k1['y'])), (int(k2['x']), int(k2['y'])), color, line_thick, cv2.LINE_AA)\n",
        "    # Face Dots (Sparse)\n",
        "    face_anchors = ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear']\n",
        "    sorted_keys = sorted(kps.keys())\n",
        "    face_counter = 0\n",
        "    for name in sorted_keys:\n",
        "        kp = kps[name]\n",
        "        if kp['conf'] > conf_thresh:\n",
        "            is_face = name.startswith('face_kp') or name in face_anchors\n",
        "            if is_face:\n",
        "                 face_counter += 1\n",
        "                 if face_counter % 2 == 0:\n",
        "                    cv2.circle(frame, (int(kp['x']), int(kp['y'])), face_rad, C_FACE_KP, -1, cv2.LINE_AA)\n",
        "    return frame\n",
        "\n",
        "def draw_seg_hq(seg_map, w, h, original_frame, blend_alpha=0.7):\n",
        "    seg_colored = BODY_PART_COLORS[seg_map]\n",
        "    seg_colored = cv2.resize(seg_colored, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "    mask = (seg_map != 0).astype(np.uint8)\n",
        "    mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "    mask = np.expand_dims(mask, axis=2)\n",
        "    blended = (seg_colored * blend_alpha + original_frame * (1 - blend_alpha)).astype(np.uint8)\n",
        "    return np.where(mask > 0, blended, original_frame).astype(np.uint8)\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESSING LOOP (Sequential)\n",
        "# ============================================================================\n",
        "print(\"\\nüé¨ INITIALIZING PROCESSING...\")\n",
        "\n",
        "# 1. READ VIDEO METADATA\n",
        "cap = cv2.VideoCapture(CLEAN_INPUT)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# Ensure even dims\n",
        "width = (width // 2) * 2; height = (height // 2) * 2\n",
        "cap.release()\n",
        "\n",
        "print(f\"   Video Info: {width}x{height}, {total_frames} frames, {fps} fps\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "# --- PASS 1: POSE ---\n",
        "print(\"\\nüèÉ PASS 1/3: POSE ESTIMATION (Loading Model...)\")\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "pose_model = torch.jit.load(POSE_MODEL_PATH, map_location=device).eval()\n",
        "\n",
        "cap = cv2.VideoCapture(CLEAN_INPUT)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "out_pose = cv2.VideoWriter(OUTPUT_POSE_AVI, fourcc, fps, (width, height))\n",
        "\n",
        "processed_count = 0\n",
        "with tqdm(total=total_frames, desc=\"Pose\") as pbar:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "\n",
        "        frame = cv2.resize(frame, (width, height))\n",
        "        tensor = preprocess(frame).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pose_out = pose_model(tensor)\n",
        "        heatmaps = (pose_out[0] if isinstance(pose_out, tuple) else pose_out)[0].cpu().numpy()\n",
        "        kps = get_keypoints(heatmaps, width, height)\n",
        "\n",
        "        result_frame = draw_pose_hq(frame.copy(), kps)\n",
        "        out_pose.write(result_frame)\n",
        "\n",
        "        processed_count += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release(); out_pose.release()\n",
        "del pose_model; gc.collect(); torch.cuda.empty_cache()\n",
        "print(f\"‚úÖ Pose Pass Done. Processed {processed_count} frames.\")\n",
        "if processed_count == 0:\n",
        "    print(\"‚ùå ERROR: No frames processed! Video read failed.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- PASS 2: SEGMENTATION ---\n",
        "print(\"\\nüèÉ PASS 2/3: SEGMENTATION (Loading Model...)\")\n",
        "seg_model = torch.jit.load(SEG_MODEL_PATH, map_location=device).eval()\n",
        "\n",
        "cap = cv2.VideoCapture(CLEAN_INPUT)\n",
        "out_seg = cv2.VideoWriter(OUTPUT_SEG_AVI, fourcc, fps, (width, height))\n",
        "\n",
        "with tqdm(total=total_frames, desc=\"Seg\") as pbar:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        frame = cv2.resize(frame, (width, height))\n",
        "\n",
        "        tensor = preprocess(frame).to(device)\n",
        "        with torch.no_grad():\n",
        "            seg_out = seg_model(tensor)\n",
        "        seg_logits = (seg_out[0] if isinstance(seg_out, tuple) else seg_out)[0].cpu().numpy()\n",
        "        seg_map = np.argmax(seg_logits, axis=0)\n",
        "\n",
        "        result_frame = draw_seg_hq(seg_map, width, height, frame.copy())\n",
        "        out_seg.write(result_frame)\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release(); out_seg.release()\n",
        "del seg_model; gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# --- PASS 3: STITCHING ---\n",
        "print(\"\\nüßµ PASS 3/3: STITCHING...\")\n",
        "cap1 = cv2.VideoCapture(OUTPUT_POSE_AVI)\n",
        "cap2 = cv2.VideoCapture(OUTPUT_SEG_AVI)\n",
        "out_final = cv2.VideoWriter(OUTPUT_COMBINED_AVI, fourcc, fps, (width * 2, height))\n",
        "\n",
        "while True:\n",
        "    r1, f1 = cap1.read()\n",
        "    r2, f2 = cap2.read()\n",
        "    if not r1 or not r2: break\n",
        "    out_final.write(np.hstack([f1, f2]))\n",
        "\n",
        "cap1.release(); cap2.release(); out_final.release()\n",
        "\n",
        "# --- CONVERT ---\n",
        "print(\"\\nüîÑ FINISHING UP (Converting to MP4)...\")\n",
        "def convert(inp, out):\n",
        "    if os.path.exists(inp):\n",
        "        subprocess.run(f'ffmpeg -y -loglevel error -i \"{inp}\" -c:v libx264 -pix_fmt yuv420p \"{out}\"', shell=True)\n",
        "        os.remove(inp)\n",
        "\n",
        "convert(OUTPUT_COMBINED_AVI, OUTPUT_FINAL)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"‚úÖ SUCCESS! Video Saved: {OUTPUT_FINAL}\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}