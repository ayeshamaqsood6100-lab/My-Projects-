# @title üé® Sapiens SEGMENTATION (Standalone)
# ============================================================================
# Meta Sapiens 1B Segmentation - 20 body part classes
# ============================================================================

import os, sys, subprocess, cv2, numpy as np, gc
from tqdm import tqdm

print("üîß Installing...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "torch", "huggingface_hub", "opencv-python", "tqdm"])

import torch
from huggingface_hub import hf_hub_download

# ============================================================================
# SETUP
# ============================================================================
try:
    from google.colab import drive
    if not os.path.exists('/content/drive'):
        drive.mount('/content/drive')
    print("‚úÖ Google Drive mounted!")
    IN_COLAB = True
except:
    IN_COLAB = False

# CONFIG
VIDEO_FILENAME = "DTQA.mp4"
BASE_PATH = "/content/drive/MyDrive/ConnectHearTestVideos" if IN_COLAB else "."
MODEL_DIR = "/content/sapiens_models" if IN_COLAB else "./sapiens_models"
os.makedirs(MODEL_DIR, exist_ok=True)

RAW_INPUT = os.path.join(BASE_PATH, VIDEO_FILENAME)
CLEAN_INPUT = "/content/cleaned_input.mp4"
OUTPUT_SEG = os.path.join(BASE_PATH, f"SEG_{VIDEO_FILENAME}")

# Check input
print(f"\nüîç Input: {RAW_INPUT}")
if not os.path.exists(RAW_INPUT):
    print(f"‚ùå ERROR: File not found!")
    sys.exit(1)

# Repair video
print("üîß Preparing video...")
subprocess.run(f'ffmpeg -y -loglevel error -i "{RAW_INPUT}" -c:v libx264 -preset fast -crf 22 "{CLEAN_INPUT}"', shell=True)

# Get video info
cap = cv2.VideoCapture(CLEAN_INPUT)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
fps = cap.get(cv2.CAP_PROP_FPS) or 30
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
width, height = (width // 2) * 2, (height // 2) * 2
cap.release()

print(f"   Video: {width}x{height}, {total_frames} frames, {fps:.1f} fps")

# ============================================================================
# DOWNLOAD MODEL
# ============================================================================
print("\nüì¶ Downloading Sapiens Segmentation 1B...")
SEG_MODEL_PATH = hf_hub_download(
    repo_id="facebook/sapiens-seg-1b-torchscript",
    filename="sapiens_1b_goliath_best_goliath_mIoU_7994_epoch_151_torchscript.pt2",
    local_dir=MODEL_DIR
)
print("‚úÖ Model downloaded")

# ============================================================================
# LOAD MODEL
# ============================================================================
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"\nüéÆ Device: {device}")

print("üîÑ Loading Segmentation model...")
seg_model = torch.jit.load(SEG_MODEL_PATH, map_location=device).eval()
print("‚úÖ Model loaded")

# ============================================================================
# BODY PART COLORS
# ============================================================================
BODY_PART_COLORS = np.array([
    [0,0,0], [255,220,200], [255,200,170], [100,200,100], [50,255,50],
    [255,165,0], [0,255,128], [255,140,0], [0,255,255], [255,100,100],
    [100,100,255], [255,100,255], [50,50,200], [200,50,200], [0,200,200],
    [200,200,0], [139,90,43], [255,210,180], [255,255,255], [255,100,150]
], dtype=np.uint8)

# ============================================================================
# PREPROCESSING & DRAWING
# ============================================================================
def preprocess(img):
    img = cv2.resize(img, (768, 1024))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
    return torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0).float()

def draw_segmentation(seg_map, w, h, original_frame, blend_alpha=0.7):
    """Draw segmentation overlay with body part colors."""
    seg_colored = BODY_PART_COLORS[seg_map % len(BODY_PART_COLORS)]
    seg_colored = cv2.resize(seg_colored, (w, h), interpolation=cv2.INTER_LINEAR)
    mask = (seg_map != 0).astype(np.uint8)
    mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_LINEAR)
    mask = np.expand_dims(mask, axis=2)
    blended = (seg_colored * blend_alpha + original_frame * (1 - blend_alpha)).astype(np.uint8)
    return np.where(mask > 0, blended, original_frame).astype(np.uint8)

# ============================================================================
# PROCESS VIDEO
# ============================================================================
print("\nüèÉ Processing...")

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter("/content/temp_seg.mp4", fourcc, fps, (width, height))

cap = cv2.VideoCapture(CLEAN_INPUT)

with tqdm(total=total_frames, desc="Segmentation") as pbar:
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame = cv2.resize(frame, (width, height))
        tensor = preprocess(frame).to(device)
        
        # Get segmentation
        with torch.no_grad():
            seg_out = seg_model(tensor)
        seg_logits = (seg_out[0] if isinstance(seg_out, tuple) else seg_out)[0].cpu().numpy()
        seg_map = np.argmax(seg_logits, axis=0)
        
        # Draw overlay
        result_frame = draw_segmentation(seg_map, width, height, frame.copy())
        
        out.write(result_frame)
        pbar.update(1)

cap.release()
out.release()

# Cleanup models
del seg_model
gc.collect()
if device == 'cuda':
    torch.cuda.empty_cache()

# ============================================================================
# FINALIZE
# ============================================================================
print("\nüîÑ Encoding...")
subprocess.run(f'ffmpeg -y -loglevel error -i "/content/temp_seg.mp4" -c:v libx264 -pix_fmt yuv420p "{OUTPUT_SEG}"', shell=True)

# Cleanup
if os.path.exists("/content/temp_seg.mp4"):
    os.remove("/content/temp_seg.mp4")
if os.path.exists(CLEAN_INPUT):
    os.remove(CLEAN_INPUT)

print("\n" + "="*60)
print("‚úÖ SUCCESS!")
print("="*60)
print(f"\nüìÅ Output: {OUTPUT_SEG}")
print("\n‚úÖ Features:")
print("   ‚Ä¢ 20 body part segmentation classes")
print("   ‚Ä¢ 70% blend overlay (adjust blend_alpha to change)")
print("   ‚Ä¢ Sapiens 1B model")
